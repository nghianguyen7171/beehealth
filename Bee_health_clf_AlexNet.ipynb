{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "data_dir = r'/media/nghia/DATA/DATA/Bee/bee_imgs/'\n",
    "PATH = r'/media/nghia/DATA/DATA/Bee/bee_imgs/bee_data.csv'\n",
    "img_path = r'/media/nghia/DATA/DATA/Bee/bee_imgs/bee_imgs'\n",
    "\n",
    "df = pd.read_csv(PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "df['health'] = df['health'].map({'healthy': 0,\n",
    "                                 'few varrao, hive beetles': 1,\n",
    "                                 'Varroa, Small Hive Beetles': 2,\n",
    "                                 'ant problems': 3,\n",
    "                                 'hive being robbed': 4,\n",
    "                                 'missing queen': 5})\n",
    "\n",
    "transform = {'train': transforms.Compose([transforms.Resize(256),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          #torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "                                          #transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                               [0.229, 0.224, 0.225])]),\n",
    "\n",
    "             'val': transforms.Compose([transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                             [0.229, 0.224, 0.225])]),\n",
    "\n",
    "             'test': transforms.Compose([transforms.Resize(256),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                              [0.229, 0.224, 0.225])])}\n",
    "\n",
    "# Check for cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class HoneyBeeDataset(Dataset):\n",
    "    # instance attributes\n",
    "    def __init__(self, df, csv_file, root_dir, transform=None):\n",
    "        self.data = df\n",
    "        self.root_dir = root_dir\n",
    "        self.labels = np.asarray(self.data.iloc[:, 6])\n",
    "        self.transform = transform\n",
    "\n",
    "    # length of the dataset passed to this class method\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # get the specific image and labels given the index\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        image = image.convert('RGB')\n",
    "        image_label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, image_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = HoneyBeeDataset(df=df,\n",
    "                          csv_file=PATH,\n",
    "                          root_dir=img_path)\n",
    "\n",
    "validation_split = 0.2\n",
    "te_split = 0.5\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "val_split = int(np.floor(validation_split * dataset_size))\n",
    "test_split = int(np.floor(te_split * val_split))\n",
    "train_indices = indices[val_split:]\n",
    "rest_indices = indices[:val_split]\n",
    "val_indices, test_indices = rest_indices[test_split:], rest_indices[:test_split]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dataset_sizes = {'train': len(train_indices), 'val': len(val_indices), 'test': len(test_indices)}\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_dataset = HoneyBeeDataset(df=df,\n",
    "                                csv_file=PATH,\n",
    "                                root_dir=img_path,\n",
    "                                transform=transform['train'])\n",
    "\n",
    "val_dataset = HoneyBeeDataset(df=df,\n",
    "                              csv_file=PATH,\n",
    "                              root_dir=img_path,\n",
    "                              transform=transform['val'])\n",
    "\n",
    "test_dataset = HoneyBeeDataset(df=df,\n",
    "                               csv_file=PATH,\n",
    "                               root_dir=img_path,\n",
    "                               transform=transform['test'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataloaders = {'train': torch.utils.data.DataLoader(train_dataset, batch_size=4, sampler=train_sampler),\n",
    "               'val': torch.utils.data.DataLoader(val_dataset, batch_size=4, sampler=valid_sampler),\n",
    "               'test': torch.utils.data.DataLoader(test_dataset, batch_size=1, sampler=test_sampler)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    #copy the best model weights\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch: {}/{}\".format(epoch, num_epochs-1))\n",
    "        print(\"=\"*10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for data in dataloaders[phase]:\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase=='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()*inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AlexNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (12): ReLU(inplace=True)\n  )\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=50176, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=6, bias=True)\n  )\n)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.MaxPool2d(2),  # kernel_size\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 192, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 384, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50176, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.features(x)\n",
    "        #print(x.shape)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        #print(x.shape)\n",
    "        x = self.classifier(h)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "OUTPUT_DIM = 6\n",
    "model = AlexNet(OUTPUT_DIM)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 10 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/34\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nghia/CNU-SEM3/AI_proj/Bee_Health/Eagle-Vision/streamlit/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9546 Acc: 0.6834\n",
      "val Loss: 0.7128 Acc: 0.7253\n",
      "Epoch: 1/34\n",
      "==========\n",
      "train Loss: 0.6843 Acc: 0.7412\n",
      "val Loss: 0.5440 Acc: 0.7911\n",
      "Epoch: 2/34\n",
      "==========\n",
      "train Loss: 0.5072 Acc: 0.7997\n",
      "val Loss: 0.3390 Acc: 0.8549\n",
      "Epoch: 3/34\n",
      "==========\n",
      "train Loss: 0.3995 Acc: 0.8366\n",
      "val Loss: 0.2721 Acc: 0.8685\n",
      "Epoch: 4/34\n",
      "==========\n",
      "train Loss: 0.3389 Acc: 0.8545\n",
      "val Loss: 0.3733 Acc: 0.8704\n",
      "Epoch: 5/34\n",
      "==========\n",
      "train Loss: 0.2886 Acc: 0.8712\n",
      "val Loss: 0.2477 Acc: 0.8936\n",
      "Epoch: 6/34\n",
      "==========\n",
      "train Loss: 0.2642 Acc: 0.8811\n",
      "val Loss: 0.2449 Acc: 0.8839\n",
      "Epoch: 7/34\n",
      "==========\n",
      "train Loss: 0.2432 Acc: 0.8925\n",
      "val Loss: 0.3442 Acc: 0.8549\n",
      "Epoch: 8/34\n",
      "==========\n",
      "train Loss: 0.2478 Acc: 0.8997\n",
      "val Loss: 0.2912 Acc: 0.8820\n",
      "Epoch: 9/34\n",
      "==========\n",
      "train Loss: 0.1666 Acc: 0.9294\n",
      "val Loss: 0.1816 Acc: 0.9207\n",
      "Epoch: 10/34\n",
      "==========\n",
      "train Loss: 0.1497 Acc: 0.9292\n",
      "val Loss: 0.1755 Acc: 0.9207\n",
      "Epoch: 11/34\n",
      "==========\n",
      "train Loss: 0.1430 Acc: 0.9357\n",
      "val Loss: 0.1801 Acc: 0.9439\n",
      "Epoch: 12/34\n",
      "==========\n",
      "train Loss: 0.1395 Acc: 0.9362\n",
      "val Loss: 0.1712 Acc: 0.9420\n",
      "Epoch: 13/34\n",
      "==========\n",
      "train Loss: 0.1321 Acc: 0.9437\n",
      "val Loss: 0.1702 Acc: 0.9362\n",
      "Epoch: 14/34\n",
      "==========\n",
      "train Loss: 0.1303 Acc: 0.9432\n",
      "val Loss: 0.1732 Acc: 0.9284\n",
      "Epoch: 15/34\n",
      "==========\n",
      "train Loss: 0.1308 Acc: 0.9398\n",
      "val Loss: 0.1831 Acc: 0.9400\n",
      "Epoch: 16/34\n",
      "==========\n",
      "train Loss: 0.1258 Acc: 0.9422\n",
      "val Loss: 0.1687 Acc: 0.9439\n",
      "Epoch: 17/34\n",
      "==========\n",
      "train Loss: 0.1197 Acc: 0.9468\n",
      "val Loss: 0.1693 Acc: 0.9323\n",
      "Epoch: 18/34\n",
      "==========\n",
      "train Loss: 0.1156 Acc: 0.9449\n",
      "val Loss: 0.1656 Acc: 0.9478\n",
      "Epoch: 19/34\n",
      "==========\n",
      "train Loss: 0.1089 Acc: 0.9553\n",
      "val Loss: 0.1640 Acc: 0.9516\n",
      "Epoch: 20/34\n",
      "==========\n",
      "train Loss: 0.1067 Acc: 0.9546\n",
      "val Loss: 0.1640 Acc: 0.9458\n",
      "Epoch: 21/34\n",
      "==========\n",
      "train Loss: 0.1070 Acc: 0.9563\n",
      "val Loss: 0.1637 Acc: 0.9439\n",
      "Epoch: 22/34\n",
      "==========\n",
      "train Loss: 0.1045 Acc: 0.9565\n",
      "val Loss: 0.1629 Acc: 0.9497\n",
      "Epoch: 23/34\n",
      "==========\n",
      "train Loss: 0.1066 Acc: 0.9548\n",
      "val Loss: 0.1613 Acc: 0.9420\n",
      "Epoch: 24/34\n",
      "==========\n",
      "train Loss: 0.1048 Acc: 0.9526\n",
      "val Loss: 0.1622 Acc: 0.9478\n",
      "Epoch: 25/34\n",
      "==========\n",
      "train Loss: 0.1047 Acc: 0.9553\n",
      "val Loss: 0.1634 Acc: 0.9458\n",
      "Epoch: 26/34\n",
      "==========\n",
      "train Loss: 0.1051 Acc: 0.9543\n",
      "val Loss: 0.1629 Acc: 0.9439\n",
      "Epoch: 27/34\n",
      "==========\n",
      "train Loss: 0.1034 Acc: 0.9548\n",
      "val Loss: 0.1638 Acc: 0.9439\n",
      "Epoch: 28/34\n",
      "==========\n",
      "train Loss: 0.1038 Acc: 0.9570\n",
      "val Loss: 0.1623 Acc: 0.9497\n",
      "Epoch: 29/34\n",
      "==========\n",
      "train Loss: 0.1045 Acc: 0.9526\n",
      "val Loss: 0.1621 Acc: 0.9458\n",
      "Epoch: 30/34\n",
      "==========\n",
      "train Loss: 0.1013 Acc: 0.9575\n",
      "val Loss: 0.1622 Acc: 0.9458\n",
      "Epoch: 31/34\n",
      "==========\n",
      "train Loss: 0.0995 Acc: 0.9582\n",
      "val Loss: 0.1622 Acc: 0.9478\n",
      "Epoch: 32/34\n",
      "==========\n",
      "train Loss: 0.1050 Acc: 0.9529\n",
      "val Loss: 0.1624 Acc: 0.9478\n",
      "Epoch: 33/34\n",
      "==========\n",
      "train Loss: 0.1039 Acc: 0.9531\n",
      "val Loss: 0.1625 Acc: 0.9478\n",
      "Epoch: 34/34\n",
      "==========\n",
      "train Loss: 0.1040 Acc: 0.9551\n",
      "val Loss: 0.1626 Acc: 0.9478\n",
      "Best val Acc: 0.951644\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 35\n",
    "# train\n",
    "model_pre = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    # no gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['test']:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            true_labels.append(labels.item())\n",
    "            outputs = model_pre(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            pred_labels.append(preds.item())\n",
    "            running_total += labels.size(0)\n",
    "            running_correct += (preds == labels).sum().item()\n",
    "    return (true_labels, pred_labels, running_correct, running_total)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 483, Total: 517\n",
      "Test Accuracy:  0.9342359767891683\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels, running_correct, running_total= test_model()\n",
    "print('Correct: {}, Total: {}'.format(running_correct, running_total))\n",
    "print('Test Accuracy: ', (running_correct/running_total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       335\n",
      "           1       0.76      0.72      0.74        61\n",
      "           2       0.68      0.71      0.70        45\n",
      "           3       1.00      1.00      1.00        41\n",
      "           4       0.97      0.94      0.95        32\n",
      "           5       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.93       517\n",
      "   macro avg       0.90      0.84      0.86       517\n",
      "weighted avg       0.93      0.93      0.93       517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(true_labels, pred_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}