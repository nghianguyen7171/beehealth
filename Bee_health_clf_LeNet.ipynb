{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "data_dir = r'/media/nghia/DATA/DATA/Bee/bee_imgs/'\n",
    "PATH = r'/media/nghia/DATA/DATA/Bee/bee_imgs/bee_data.csv'\n",
    "img_path = r'/media/nghia/DATA/DATA/Bee/bee_imgs/bee_imgs'\n",
    "\n",
    "df = pd.read_csv(PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "df['health'] = df['health'].map({'healthy': 0,\n",
    "                                 'few varrao, hive beetles': 1,\n",
    "                                 'Varroa, Small Hive Beetles': 2,\n",
    "                                 'ant problems': 3,\n",
    "                                 'hive being robbed': 4,\n",
    "                                 'missing queen': 5})\n",
    "\n",
    "transform = {'train': transforms.Compose([transforms.Resize(256),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          #torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "                                          #transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                               [0.229, 0.224, 0.225])]),\n",
    "\n",
    "             'val': transforms.Compose([transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                             [0.229, 0.224, 0.225])]),\n",
    "\n",
    "             'test': transforms.Compose([transforms.Resize(256),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                              [0.229, 0.224, 0.225])])}\n",
    "\n",
    "# Check for cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class HoneyBeeDataset(Dataset):\n",
    "    # instance attributes\n",
    "    def __init__(self, df, csv_file, root_dir, transform=None):\n",
    "        self.data = df\n",
    "        self.root_dir = root_dir\n",
    "        self.labels = np.asarray(self.data.iloc[:, 6])\n",
    "        self.transform = transform\n",
    "\n",
    "    # length of the dataset passed to this class method\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # get the specific image and labels given the index\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        image = image.convert('RGB')\n",
    "        image_label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, image_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = HoneyBeeDataset(df=df,\n",
    "                          csv_file=PATH,\n",
    "                          root_dir=img_path)\n",
    "\n",
    "validation_split = 0.2\n",
    "te_split = 0.5\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "val_split = int(np.floor(validation_split * dataset_size))\n",
    "test_split = int(np.floor(te_split * val_split))\n",
    "train_indices = indices[val_split:]\n",
    "rest_indices = indices[:val_split]\n",
    "val_indices, test_indices = rest_indices[test_split:], rest_indices[:test_split]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dataset_sizes = {'train': len(train_indices), 'val': len(val_indices), 'test': len(test_indices)}\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_dataset = HoneyBeeDataset(df=df,\n",
    "                                csv_file=PATH,\n",
    "                                root_dir=img_path,\n",
    "                                transform=transform['train'])\n",
    "\n",
    "val_dataset = HoneyBeeDataset(df=df,\n",
    "                              csv_file=PATH,\n",
    "                              root_dir=img_path,\n",
    "                              transform=transform['val'])\n",
    "\n",
    "test_dataset = HoneyBeeDataset(df=df,\n",
    "                               csv_file=PATH,\n",
    "                               root_dir=img_path,\n",
    "                               transform=transform['test'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataloaders = {'train': torch.utils.data.DataLoader(train_dataset, batch_size=4, sampler=train_sampler),\n",
    "               'val': torch.utils.data.DataLoader(val_dataset, batch_size=4, sampler=valid_sampler),\n",
    "               'test': torch.utils.data.DataLoader(test_dataset, batch_size=1, sampler=test_sampler)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    #copy the best model weights\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch: {}/{}\".format(epoch, num_epochs-1))\n",
    "        print(\"=\"*10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for data in dataloaders[phase]:\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase=='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()*inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LeNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "LeNet(\n  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc_1): Linear(in_features=44944, out_features=16, bias=True)\n  (fc_2): Linear(in_features=16, out_features=16, bias=True)\n  (fc_3): Linear(in_features=16, out_features=6, bias=True)\n)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,\n",
    "                               out_channels=6,\n",
    "                               kernel_size=5)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=6,\n",
    "                               out_channels=16,\n",
    "                               kernel_size=5)\n",
    "\n",
    "        self.fc_1 = nn.Linear(44944, 16)\n",
    "        self.fc_2 = nn.Linear(16, 16)\n",
    "        self.fc_3 = nn.Linear(16, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x = [batch size, 3, 100, 100]\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        # x = [batch size, 6, 96, 96]\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        #print(x.shape)\n",
    "        # x = [batch size, 6, 48, 48]\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        # x = [batch size, 6, 44, 44]\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        #print(x.shape)\n",
    "        # x = [batch size, 6, 22, 22]\n",
    "\n",
    "        x = F.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        #print(x.shape)\n",
    "        # x = [batch size, 16*4*4 = 256]\n",
    "\n",
    "        h = x\n",
    "\n",
    "        x = self.fc_1(x)\n",
    "\n",
    "        # x = [batch size, 120]\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc_2(x)\n",
    "\n",
    "        # x = batch size, 84]\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc_3(x)\n",
    "\n",
    "        # x = [batch size, output dim]\n",
    "\n",
    "        return x\n",
    "\n",
    "OUTPUT_DIM = 6\n",
    "model = LeNet(OUTPUT_DIM)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 10 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/34\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nghia/CNU-SEM3/AI_proj/Bee_Health/Eagle-Vision/streamlit/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8334 Acc: 0.7078\n",
      "val Loss: 0.4756 Acc: 0.8240\n",
      "Epoch: 1/34\n",
      "==========\n",
      "train Loss: 0.5223 Acc: 0.7997\n",
      "val Loss: 0.4500 Acc: 0.8259\n",
      "Epoch: 2/34\n",
      "==========\n",
      "train Loss: 0.4353 Acc: 0.8260\n",
      "val Loss: 0.3636 Acc: 0.8569\n",
      "Epoch: 3/34\n",
      "==========\n",
      "train Loss: 0.3613 Acc: 0.8424\n",
      "val Loss: 0.2840 Acc: 0.8743\n",
      "Epoch: 4/34\n",
      "==========\n",
      "train Loss: 0.3391 Acc: 0.8519\n",
      "val Loss: 0.2744 Acc: 0.8859\n",
      "Epoch: 5/34\n",
      "==========\n",
      "train Loss: 0.3108 Acc: 0.8591\n",
      "val Loss: 0.4842 Acc: 0.8104\n",
      "Epoch: 6/34\n",
      "==========\n",
      "train Loss: 0.4266 Acc: 0.8306\n",
      "val Loss: 0.3912 Acc: 0.8433\n",
      "Epoch: 7/34\n",
      "==========\n",
      "train Loss: 0.3962 Acc: 0.8461\n",
      "val Loss: 0.3563 Acc: 0.8685\n",
      "Epoch: 8/34\n",
      "==========\n",
      "train Loss: 0.3579 Acc: 0.8574\n",
      "val Loss: 0.3137 Acc: 0.8762\n",
      "Epoch: 9/34\n",
      "==========\n",
      "train Loss: 0.2509 Acc: 0.8835\n",
      "val Loss: 0.2543 Acc: 0.8839\n",
      "Epoch: 10/34\n",
      "==========\n",
      "train Loss: 0.2286 Acc: 0.8862\n",
      "val Loss: 0.2565 Acc: 0.8781\n",
      "Epoch: 11/34\n",
      "==========\n",
      "train Loss: 0.2161 Acc: 0.8925\n",
      "val Loss: 0.2577 Acc: 0.8781\n",
      "Epoch: 12/34\n",
      "==========\n",
      "train Loss: 0.2068 Acc: 0.8942\n",
      "val Loss: 0.2623 Acc: 0.9014\n",
      "Epoch: 13/34\n",
      "==========\n",
      "train Loss: 0.2005 Acc: 0.8937\n",
      "val Loss: 0.2515 Acc: 0.8897\n",
      "Epoch: 14/34\n",
      "==========\n",
      "train Loss: 0.1908 Acc: 0.9007\n",
      "val Loss: 0.2518 Acc: 0.8878\n",
      "Epoch: 15/34\n",
      "==========\n",
      "train Loss: 0.1854 Acc: 0.9002\n",
      "val Loss: 0.2571 Acc: 0.8878\n",
      "Epoch: 16/34\n",
      "==========\n",
      "train Loss: 0.1822 Acc: 0.9033\n",
      "val Loss: 0.2645 Acc: 0.8975\n",
      "Epoch: 17/34\n",
      "==========\n",
      "train Loss: 0.1790 Acc: 0.9045\n",
      "val Loss: 0.2553 Acc: 0.8975\n",
      "Epoch: 18/34\n",
      "==========\n",
      "train Loss: 0.1736 Acc: 0.9079\n",
      "val Loss: 0.2528 Acc: 0.8917\n",
      "Epoch: 19/34\n",
      "==========\n",
      "train Loss: 0.1629 Acc: 0.9203\n",
      "val Loss: 0.2526 Acc: 0.9014\n",
      "Epoch: 20/34\n",
      "==========\n",
      "train Loss: 0.1618 Acc: 0.9178\n",
      "val Loss: 0.2540 Acc: 0.8956\n",
      "Epoch: 21/34\n",
      "==========\n",
      "train Loss: 0.1612 Acc: 0.9205\n",
      "val Loss: 0.2559 Acc: 0.8994\n",
      "Epoch: 22/34\n",
      "==========\n",
      "train Loss: 0.1604 Acc: 0.9193\n",
      "val Loss: 0.2568 Acc: 0.8956\n",
      "Epoch: 23/34\n",
      "==========\n",
      "train Loss: 0.1598 Acc: 0.9203\n",
      "val Loss: 0.2567 Acc: 0.8975\n",
      "Epoch: 24/34\n",
      "==========\n",
      "train Loss: 0.1590 Acc: 0.9212\n",
      "val Loss: 0.2568 Acc: 0.8994\n",
      "Epoch: 25/34\n",
      "==========\n",
      "train Loss: 0.1584 Acc: 0.9212\n",
      "val Loss: 0.2582 Acc: 0.8994\n",
      "Epoch: 26/34\n",
      "==========\n",
      "train Loss: 0.1577 Acc: 0.9207\n",
      "val Loss: 0.2587 Acc: 0.8975\n",
      "Epoch: 27/34\n",
      "==========\n",
      "train Loss: 0.1569 Acc: 0.9256\n",
      "val Loss: 0.2595 Acc: 0.9014\n",
      "Epoch: 28/34\n",
      "==========\n",
      "train Loss: 0.1562 Acc: 0.9246\n",
      "val Loss: 0.2606 Acc: 0.9014\n",
      "Epoch: 29/34\n",
      "==========\n",
      "train Loss: 0.1550 Acc: 0.9227\n",
      "val Loss: 0.2602 Acc: 0.9014\n",
      "Epoch: 30/34\n",
      "==========\n",
      "train Loss: 0.1549 Acc: 0.9232\n",
      "val Loss: 0.2600 Acc: 0.9014\n",
      "Epoch: 31/34\n",
      "==========\n",
      "train Loss: 0.1548 Acc: 0.9227\n",
      "val Loss: 0.2599 Acc: 0.8994\n",
      "Epoch: 32/34\n",
      "==========\n",
      "train Loss: 0.1547 Acc: 0.9241\n",
      "val Loss: 0.2598 Acc: 0.8994\n",
      "Epoch: 33/34\n",
      "==========\n",
      "train Loss: 0.1546 Acc: 0.9236\n",
      "val Loss: 0.2597 Acc: 0.8975\n",
      "Epoch: 34/34\n",
      "==========\n",
      "train Loss: 0.1545 Acc: 0.9229\n",
      "val Loss: 0.2598 Acc: 0.8975\n",
      "Best val Acc: 0.901354\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 35\n",
    "# train\n",
    "model_pre = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    # no gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['test']:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            true_labels.append(labels.item())\n",
    "            outputs = model_pre(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            pred_labels.append(preds.item())\n",
    "            running_total += labels.size(0)\n",
    "            running_correct += (preds == labels).sum().item()\n",
    "    return (true_labels, pred_labels, running_correct, running_total)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 470, Total: 517\n",
      "Test Accuracy:  0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels, running_correct, running_total= test_model()\n",
    "print('Correct: {}, Total: {}'.format(running_correct, running_total))\n",
    "print('Test Accuracy: ', (running_correct/running_total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       352\n",
      "           1       0.63      0.71      0.67        55\n",
      "           2       0.69      0.53      0.60        45\n",
      "           3       1.00      0.95      0.97        38\n",
      "           4       0.91      0.84      0.87        25\n",
      "           5       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.91       517\n",
      "   macro avg       0.87      0.84      0.85       517\n",
      "weighted avg       0.91      0.91      0.91       517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(true_labels, pred_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}